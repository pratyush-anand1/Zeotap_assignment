{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _cext: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# importing neccessary librararies \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\TRATYUSH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\__init__.py:264\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[0;32m    260\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    261\u001b[0m                               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 264\u001b[0m \u001b[43m_check_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;66;03m# The decorator ensures this always returns the same handler (and it is only\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;66;03m# attached once).\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcache\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_handler\u001b[39m():\n",
      "File \u001b[1;32mc:\\Users\\TRATYUSH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\__init__.py:258\u001b[0m, in \u001b[0;36m_check_versions\u001b[1;34m()\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ft2font  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m modname, minver \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    252\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcycler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.10\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    253\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdateutil\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.7\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyparsing\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.3.1\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    257\u001b[0m ]:\n\u001b[1;32m--> 258\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    261\u001b[0m                           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\TRATYUSH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\TRATYUSH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\kiwisolver\\__init__.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2013-2022, Nucleic Development Team.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# The full license is in the file LICENSE, distributed with this software.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# --------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     Constraint,\n\u001b[0;32m     10\u001b[0m     Expression,\n\u001b[0;32m     11\u001b[0m     Solver,\n\u001b[0;32m     12\u001b[0m     Term,\n\u001b[0;32m     13\u001b[0m     Variable,\n\u001b[0;32m     14\u001b[0m     __kiwi_version__,\n\u001b[0;32m     15\u001b[0m     __version__,\n\u001b[0;32m     16\u001b[0m     strength,\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     BadRequiredStrength,\n\u001b[0;32m     20\u001b[0m     DuplicateConstraint,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     UnsatisfiableConstraint,\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     27\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBadRequiredStrength\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuplicateConstraint\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__kiwi_version__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     42\u001b[0m ]\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _cext: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "# importing neccessary librararies \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#couldn't do it properly or convincingly because I don't know my matplotlib and seaborn lib were not working at all SORRY!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv datasets using pandas library\n",
    "customers = pd.read_csv('Customers.csv')\n",
    "products = pd.read_csv('Products.csv')\n",
    "transactions = pd.read_csv('Transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID        CustomerName         Region  SignupDate\n",
      "0      C0001    Lawrence Carroll  South America  2022-07-10\n",
      "1      C0002      Elizabeth Lutz           Asia  2022-02-13\n",
      "2      C0003      Michael Rivera  South America  2024-03-07\n",
      "3      C0004  Kathleen Rodriguez  South America  2022-10-09\n",
      "4      C0005         Laura Weber           Asia  2022-08-15\n",
      "  ProductID              ProductName     Category   Price\n",
      "0      P001     ActiveWear Biography        Books  169.30\n",
      "1      P002    ActiveWear Smartwatch  Electronics  346.30\n",
      "2      P003  ComfortLiving Biography        Books   44.12\n",
      "3      P004            BookWorld Rug   Home Decor   95.69\n",
      "4      P005          TechPro T-Shirt     Clothing  429.31\n",
      "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue   Price  \n",
      "0      300.68  300.68  \n",
      "1      300.68  300.68  \n",
      "2      300.68  300.68  \n",
      "3      601.36  300.68  \n",
      "4      902.04  300.68  \n"
     ]
    }
   ],
   "source": [
    "print(customers.head())\n",
    "print(products.head())\n",
    "print(transactions.head())\n",
    "\n",
    "# this is to check whether the loading of datasets was succesful or not\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will have to merge the datasets carefully so that we can analyze all three together and perform EDA. Like in the above three datasets we will first merge transactions and customer datasets on the refefernce of \"CUSTOMER ID\" column and then merge products dataset with the resultant merged dataset of transactions and customers on the reference of \"PRODUCT ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(transactions, customers, on=\"CustomerID\", how=\"inner\")\n",
    "merged_data = pd.merge(merged_data, products, on=\"ProductID\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values: TransactionID      0\n",
      "CustomerID         0\n",
      "ProductID          0\n",
      "TransactionDate    0\n",
      "Quantity           0\n",
      "TotalValue         0\n",
      "Price_x            0\n",
      "CustomerName       0\n",
      "Region             0\n",
      "SignupDate         0\n",
      "ProductName        0\n",
      "Category           0\n",
      "Price_y            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"missing values:\", merged_data.isnull().sum())\n",
    "\n",
    "# in this we have checked column wise total missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>TotalValue</th>\n",
       "      <th>Price_x</th>\n",
       "      <th>Price_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.537000</td>\n",
       "      <td>689.995560</td>\n",
       "      <td>272.55407</td>\n",
       "      <td>272.55407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.117981</td>\n",
       "      <td>493.144478</td>\n",
       "      <td>140.73639</td>\n",
       "      <td>140.73639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.080000</td>\n",
       "      <td>16.08000</td>\n",
       "      <td>16.08000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>295.295000</td>\n",
       "      <td>147.95000</td>\n",
       "      <td>147.95000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>588.880000</td>\n",
       "      <td>299.93000</td>\n",
       "      <td>299.93000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1011.660000</td>\n",
       "      <td>404.40000</td>\n",
       "      <td>404.40000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1991.040000</td>\n",
       "      <td>497.76000</td>\n",
       "      <td>497.76000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Quantity   TotalValue     Price_x     Price_y\n",
       "count  1000.000000  1000.000000  1000.00000  1000.00000\n",
       "mean      2.537000   689.995560   272.55407   272.55407\n",
       "std       1.117981   493.144478   140.73639   140.73639\n",
       "min       1.000000    16.080000    16.08000    16.08000\n",
       "25%       2.000000   295.295000   147.95000   147.95000\n",
       "50%       3.000000   588.880000   299.93000   299.93000\n",
       "75%       4.000000  1011.660000   404.40000   404.40000\n",
       "max       4.000000  1991.040000   497.76000   497.76000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.describe()\n",
    "# these are some statistics related to merged dataset that we formed like quartiles and deviations etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will start few data analysis related to business insights and how will we communivcate to the organization regarding  our insights which should inturn help them in gaining profits and identify more profit groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region\n",
      "South America    219352.56\n",
      "Europe           166254.63\n",
      "North America    152313.40\n",
      "Asia             152074.97\n",
      "Name: TotalValue, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1) let's first see in which region are we doing the best will have to focus more in that region rather than getting lighter in that\n",
    "revenue = (merged_data.groupby('Region')['TotalValue'].sum().sort_values(ascending=False))\n",
    "print(revenue)\n",
    "# so according to this we get maximum transaction amount from south America region followed by Europe and least in Asia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerName\n",
      "Abigail Jones           11\n",
      "William Adams           11\n",
      "Paul Parsons            10\n",
      "Matthew Johnson         10\n",
      "Gerald Hines            10\n",
      "David Li                10\n",
      "Hunter Fuller            9\n",
      "Nancy Walker             9\n",
      "Misty Higgins            9\n",
      "Belinda Garner           9\n",
      "Juan Mcdaniel            9\n",
      "Jessica Warren           8\n",
      "Francisco Young          8\n",
      "Laura Gilbert            8\n",
      "Mark Cox                 8\n",
      "Laura Bennett            8\n",
      "Michael Atkinson         8\n",
      "Mrs. Kimberly Wright     8\n",
      "Kathleen Rodriguez       8\n",
      "Wayne Stone              8\n",
      "Bruce Rhodes             8\n",
      "Ricky Gutierrez          8\n",
      "Edwin Watson             8\n",
      "Joseph Ortiz Jr.         8\n",
      "Jennifer King            8\n",
      "Rodney Eaton             8\n",
      "Jason Yates              8\n",
      "Kelsey Roberts           8\n",
      "Robert Blanchard         8\n",
      "Anna Ball                8\n",
      "Jennifer Pena            8\n",
      "David Davis              7\n",
      "Michele Cooley           7\n",
      "Lindsay Perez            7\n",
      "Stacy Cook               7\n",
      "Travis Campbell          7\n",
      "Brian Parker             7\n",
      "Michael Williams         7\n",
      "Samantha Frank           7\n",
      "Tina Jacobs              7\n",
      "Lauren Buchanan          7\n",
      "Beth Cardenas            7\n",
      "Nicholas Ellis           7\n",
      "Lindsey Deleon           7\n",
      "Charles Hamilton         7\n",
      "Michelle Brown           7\n",
      "Kevin May                7\n",
      "Aimee Taylor             7\n",
      "Corey Ruiz               7\n",
      "Ryan Hampton             6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2) Let's see who are the most frequent customer on the basis of payment count so that we are able to keep them intact with us and give special attention to them so that we don't lose them as our customer\n",
    "frequent_customers = (\n",
    "    merged_data['CustomerName']\n",
    "    .value_counts()\n",
    "    .head(50)\n",
    ")\n",
    "print(frequent_customers)\n",
    "# this is the list of 50 customers who are most frequent but is this all to conclude that they are the one who shall be given special attention\n",
    "# No we shall see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomerName\n",
      "Paul Parsons            10673.87\n",
      "Bruce Rhodes             8040.39\n",
      "Gerald Hines             7663.70\n",
      "William Adams            7634.45\n",
      "Aimee Taylor             7572.91\n",
      "Anna Ball                7111.32\n",
      "Mrs. Kimberly Wright     7073.28\n",
      "Jennifer Pena            6819.57\n",
      "Rodney Eaton             6715.72\n",
      "Juan Mcdaniel            6708.10\n",
      "Travis Campbell          6604.23\n",
      "Laura Bennett            6579.10\n",
      "Matthew Johnson          6210.53\n",
      "Lindsey Deleon           6149.78\n",
      "Michael Atkinson         6132.36\n",
      "Benjamin Mcclure         6072.92\n",
      "Brian Parker             6044.63\n",
      "Michael Williams         6021.80\n",
      "Lauren Buchanan          6000.56\n",
      "Mark Cox                 5950.42\n",
      "Misty Higgins            5848.97\n",
      "Francisco Young          5808.04\n",
      "Benjamin Anderson        5780.43\n",
      "Tiffany Cain             5775.28\n",
      "Wayne Stone              5771.27\n",
      "Nicholas Ellis           5699.57\n",
      "Beth Cardenas            5627.83\n",
      "Cynthia Clayton          5610.25\n",
      "Kelsey Roberts           5550.99\n",
      "Abigail Jones            5487.25\n",
      "Matthew Rogers           5457.79\n",
      "Robert Blanchard         5419.92\n",
      "Michelle Brown           5377.83\n",
      "Kathleen Rodriguez       5354.88\n",
      "Albert Burke             5316.46\n",
      "Nancy Walker             5294.99\n",
      "Kevin May                5231.26\n",
      "Nicholas Cain            5158.65\n",
      "Michael Cowan            5145.35\n",
      "Corey Ruiz               5072.55\n",
      "Karen Clements MD        5053.83\n",
      "Clinton Gomez            5003.45\n",
      "Laura Watts              4982.88\n",
      "Joshua Preston           4980.77\n",
      "Logan Harris             4931.74\n",
      "David Davis              4848.54\n",
      "Joseph Ortiz Jr.         4812.10\n",
      "Ryan Hampton             4807.45\n",
      "Edwin Watson             4802.24\n",
      "Tyler Haynes             4781.85\n",
      "Name: TotalValue, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 3) Top customers according to total payment amounts\n",
    "top_customers = merged_data.groupby('CustomerName')['TotalValue'].sum().sort_values(ascending=False).head(50)\n",
    "print(top_customers)\n",
    "#Now you can see that the few top customers in previous insight are not present here so we need to take both into consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CustomerName  TransactionCount  TotalTransactionAmount\n",
      "196      William Adams                11                 7634.45\n",
      "1        Abigail Jones                11                 5487.25\n",
      "63        Gerald Hines                10                 7663.70\n",
      "153       Paul Parsons                10                10673.87\n",
      "47            David Li                10                 4271.61\n",
      "..                 ...               ...                     ...\n",
      "184          Tina Ford                 1                  137.54\n",
      "143  Mr. Manuel Conway                 1                  922.41\n",
      "74        James Murphy                 1                   82.36\n",
      "46      David Gonzalez                 1                 1007.52\n",
      "198     Zachary Turner                 1                  396.34\n",
      "\n",
      "[199 rows x 3 columns]\n",
      "\n",
      "Correlation Between Transaction Count and Total Transaction Amount:\n",
      " 0.7947204249687639\n"
     ]
    }
   ],
   "source": [
    "# here we will be checking the correlation between the two metrics we ggot before\n",
    "\n",
    "\n",
    "transaction_count = merged_data.groupby('CustomerName')['TransactionID'].count().reset_index()\n",
    "transaction_count.columns = ['CustomerName', 'TransactionCount']\n",
    "\n",
    "# calculate total transaction amount for each customer\n",
    "total_transaction_amount = merged_data.groupby('CustomerName')['TotalValue'].sum().reset_index()\n",
    "total_transaction_amount.columns = ['CustomerName', 'TotalTransactionAmount']\n",
    "\n",
    "# merge both metrics into a single DataFrame\n",
    "customer_metrics = pd.merge(transaction_count, total_transaction_amount, on='CustomerName')\n",
    "\n",
    "# sorting by transaction count and amount\n",
    "customer_metrics_sorted = customer_metrics.sort_values(by='TransactionCount', ascending=False)\n",
    "\n",
    "# Calculate correlation between transaction count and total transaction amount\n",
    "correlation = customer_metrics['TransactionCount'].corr(customer_metrics['TotalTransactionAmount'])\n",
    "\n",
    "# Display the results\n",
    "print( customer_metrics_sorted)\n",
    "print(\"\\nCorrelation Between Transaction Count and Total Transaction Amount:\\n\", correlation)\n",
    "\n",
    "# so this conveys that we can conclude from  any one of the above two metrics since correlation is strong approx 0.8\n",
    "# this says strong linear realtionship between them as one increases other tends to increase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProductName\n",
      "ActiveWear Smartwatch    40\n",
      "SoundWave Headphones     38\n",
      "BookWorld Biography      30\n",
      "ActiveWear Rug           29\n",
      "SoundWave Cookbook       29\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4) Now lets see which is most frequently bought item \n",
    "\n",
    "top_product = merged_data['ProductName'].value_counts().head(5)\n",
    "print(top_product)\n",
    "\n",
    "# so most bought product is AcytiveWear Smartwatch closely followed by few more products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\n",
      "Books          192147.47\n",
      "Electronics    180783.50\n",
      "Clothing       166170.66\n",
      "Home Decor     150893.93\n",
      "Name: TotalValue, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 5) Now let's see what is which product category was contributing hoghest in the revenue\n",
    "\n",
    "cat_revenue = merged_data.groupby('Category')['TotalValue'].sum().sort_values(ascending=False)\n",
    "print(cat_revenue)\n",
    "\n",
    "# this tells us otherwise means in most bought product it was dominated by electronics in the top but actually its the books first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Quantity  TotalValue\n",
      "Quantity    1.000000    0.609972\n",
      "TotalValue  0.609972    1.000000\n"
     ]
    }
   ],
   "source": [
    "correlation = merged_data[['Quantity', 'TotalValue']].corr()\n",
    "print( correlation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
